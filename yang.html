<!DOCTYPE html>

<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
     <meta charset="utf-8" />
     <title>Delving into Deep Imbalanced Regression by Yuzhe Yang et al.</title>
</head>
<body>
     <h1>Reference</h1>
     <h2>Title</h2>
     <p>Delving into Deep Imbalanced Regression</p>
     <h2>Authors</h2>
     <p>Yuzhe Yang</p>
     <p>Kaiwen Zha</p>
     <p>Ying-Cong Chen</p>
     <p>Hao Wang</p>
     <p>Dina Katabi</p>
     <h2>Year</h2>
     <p>2021</p>
     <h2>Venue</h2>
     <p>CVPR</p>
     <h2>Paper Numbers</h2>
     <p>1-23</p>
     <h1>Paper Link</h1>
     <a href="https://arxiv.org/pdf/2102.09554.pdf">Delving into Deep Imbalanced Regression</a>
     <h1>Summary</h1>
     <p>
          This paper is all about smoothing. The paper focuses on imbalanced distributions with continuous output. They propose smoothing by
          labels and smoothing by features to improve performance.
     </p>
     <p>
          Label distribution smoothing (LDS) uses a kernel function to smooth out the label distribution so that the error distribution and label density
          distribution are higher correlated. This allows then to apply techniques for addressing class imbalance problems. It itself does NOT fix class imbalance.
     </p>
     <p>
          Feature Distribution Smoothing (FDS) is motivated by the assumption that the output is continuous so the feature space should also be continuous. Thus, by collecting
          the feature mean and variance and applying a smoothing kernel function, a new smoothed representation can be generated. This is integrated into NN by "inserting a 
          feature calibration layer after the final feature map."
     </p>
     <p>
          The evaluation metrics show LDS and FDS having almost constant improvement across different datasets and methods. It can also be noted the RRT method is used
          in this paper, and it shows a marked improvement over the other methods for balancing class data.
     </p>
</body>
</html>
